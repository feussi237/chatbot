etape dans la conception dy chatbot avec pytorch et nltk

1) Theory + NLP concept (stemming, tokenization, back of words)
2) Create training data
3) PyTorch model and training
4) save and load model and implement the chat

import torch
import json
import random
from nltk_utils import tokenize, stem, bag_of_words
from model import NeuralNet


device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')

with open('intents.json', 'r', encoding='utf-8') as f:
    intents= json.load(f)

FILE = "data.pth"
data = torch.load(FILE)

input_size = data['input_size']
output_size = data['output_size']
hidden_size = data['hidden_size']
all_words = data['all_words']
tags = data['tags']
model_state = data['model_state']

model= NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)
model.eval()

bot_name = "ChatBot"


def get_responses(msg):
    sentence = tokenize(msg)
    X=bag_of_words(sentence, all_words)
    X=X.reshape(1, X.shape[0])
    X=torch.from_numpy(X)

    output= model(X)
    _, predicted = torch.max(output, dim=1)
    tag = tags[predicted.item()]

    probs = torch.softmax(output, dim=1)
    prob = probs[0][predicted.item()]

    if prob.item() > 0.3:
     for intent in intents['intents']:
        if tag == intent['tag']:
            return random.choice(intent['responses'])
    return "I don't understand..."

if __name__ == "__main__":
    print("Bienvenue a WebAgency! ('bye' pour terminer la discussion)")
    while True:
        sentence = input("Toi: ")
        if sentence == 'bye':
            break
        response = get_responses(sentence)
        print(response)